{
 "cells": [
  {
   "cell_type": "code",
   "id": "319e799a8b49e7fb",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-09T13:04:37.838089Z",
     "start_time": "2024-10-09T13:04:31.319028Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import onnx\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T13:04:37.853090Z",
     "start_time": "2024-10-09T13:04:37.840090Z"
    }
   },
   "cell_type": "code",
   "source": "# ort_session = ort.InferenceSession(r'models/arcface.onnx', providers=['CUDAExecutionProvider'])",
   "id": "432f3eeb6226b8c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T13:04:37.868089Z",
     "start_time": "2024-10-09T13:04:37.854089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ArcFaceONNX:\n",
    "    def __init__(self, model_file=None, session=None):\n",
    "        assert model_file is not None\n",
    "        self.model_file = model_file\n",
    "        self.session = session\n",
    "        self.taskname = 'recognition'\n",
    "        find_sub = False\n",
    "        find_mul = False\n",
    "        model = onnx.load(self.model_file)\n",
    "        graph = model.graph\n",
    "        for nid, node in enumerate(graph.node[:8]):\n",
    "            #print(nid, node.name)\n",
    "            if node.name.startswith('Sub') or node.name.startswith('_minus'):\n",
    "                find_sub = True\n",
    "            if node.name.startswith('Mul') or node.name.startswith('_mul'):\n",
    "                find_mul = True\n",
    "        if find_sub and find_mul:\n",
    "            #mxnet arcface model\n",
    "            input_mean = 0.0\n",
    "            input_std = 1.0\n",
    "        else:\n",
    "            input_mean = 127.5\n",
    "            input_std = 127.5\n",
    "        self.input_mean = input_mean\n",
    "        self.input_std = input_std\n",
    "        #print('input mean and std:', self.input_mean, self.input_std)\n",
    "        if self.session is None:\n",
    "            self.session = onnxruntime.InferenceSession(self.model_file, providers=['CUDAExecutionProvider'])\n",
    "        input_cfg = self.session.get_inputs()[0]\n",
    "        input_shape = input_cfg.shape\n",
    "        input_name = input_cfg.name\n",
    "        self.input_size = tuple(input_shape[2:4][::-1])\n",
    "        self.input_shape = input_shape\n",
    "        outputs = self.session.get_outputs()\n",
    "        output_names = []\n",
    "        for out in outputs:\n",
    "            output_names.append(out.name)\n",
    "        self.input_name = input_name\n",
    "        self.output_names = output_names\n",
    "        assert len(self.output_names)==1\n",
    "        self.output_shape = outputs[0].shape\n",
    "\n",
    "    def prepare(self, ctx_id, **kwargs):\n",
    "        if ctx_id<0:\n",
    "            self.session.set_providers(['CUDAExecutionProvider'])\n",
    "\n",
    "    # def get(self, img, face):\n",
    "    #     aimg = face_align.norm_crop(img, landmark=face.kps, image_size=self.input_size[0])\n",
    "    #     face.embedding = self.get_feat(aimg).flatten()\n",
    "    #     return face.embedding\n",
    "\n",
    "    def compute_sim(self, feat1, feat2):\n",
    "        from numpy.linalg import norm\n",
    "        feat1 = feat1.ravel()\n",
    "        feat2 = feat2.ravel()\n",
    "        sim = np.dot(feat1, feat2) / (norm(feat1) * norm(feat2))\n",
    "        return sim\n",
    "\n",
    "    def get_feat(self, imgs):\n",
    "        if not isinstance(imgs, list):\n",
    "            imgs = [imgs]\n",
    "        input_size = self.input_size\n",
    "        \n",
    "        blob = cv2.dnn.blobFromImages(imgs, 1.0 / self.input_std, input_size,\n",
    "                                      (self.input_mean, self.input_mean, self.input_mean), swapRB=True)\n",
    "        net_out = self.session.run(self.output_names, {self.input_name: blob})[0]\n",
    "        return net_out\n",
    "\n",
    "    def forward(self, batch_data):\n",
    "        blob = (batch_data - self.input_mean) / self.input_std\n",
    "        net_out = self.session.run(self.output_names, {self.input_name: blob})[0]\n",
    "        return net_out"
   ],
   "id": "7c241029640cec33",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T13:04:39.174514Z",
     "start_time": "2024-10-09T13:04:37.869090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedder_r100 = ArcFaceONNX(r'models/arcface.onnx')\n",
    "embedder_r50 = ArcFaceONNX(r'models/w600k_r50.onnx')"
   ],
   "id": "5af2da77168c4304",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T13:04:39.189515Z",
     "start_time": "2024-10-09T13:04:39.175514Z"
    }
   },
   "cell_type": "code",
   "source": "embedder_r50.session.get_session_options()",
   "id": "2abd7dc97cf6ee38",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<onnxruntime.capi.onnxruntime_pybind11_state.SessionOptions at 0x1f5328f2d70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:08:26.374730Z",
     "start_time": "2024-10-08T12:08:26.359730Z"
    }
   },
   "cell_type": "code",
   "source": "onnxruntime.get_available_providers()",
   "id": "c81347da5b9a4bff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:08:29.951012Z",
     "start_time": "2024-10-08T12:08:28.142007Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "614680c5d18cdb3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 7,
   "source": [
    "dataset = ImageFolder(root=r'D:\\data\\biometrics_hack\\casia_webface', transform=np.asarray)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=6)"
   ],
   "id": "8b4dca7d6a8e0ed8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:08:29.966012Z",
     "start_time": "2024-10-08T12:08:29.953014Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ff453e7ee659edf5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:08:33.536667Z",
     "start_time": "2024-10-08T12:08:29.967012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emb_r100 = embedder_r100.get_feat(np.asarray(dataset[0][0]))\n",
    "emb_r50 = embedder_r50.get_feat(np.asarray(dataset[0][0]))"
   ],
   "id": "14eb08df9bfa22a2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:08:33.626669Z",
     "start_time": "2024-10-08T12:08:33.537668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Получение списка классов (идентичностей)\n",
    "classes = dataset.classes  # Список имён классов\n",
    "class_to_idx = dataset.class_to_idx  # Словарь: имя класса -> индекс\n",
    "\n",
    "# Получение индексов для каждого класса\n",
    "class_indices = {}\n",
    "for idx, (path, label) in enumerate(dataset.samples):\n",
    "    class_indices.setdefault(label, []).append(idx)\n",
    "\n",
    "# Выбор случайных 100 идентичностей для тестовой выборки\n",
    "num_test_classes = 100\n",
    "test_classes = np.random.choice(list(class_indices.keys()), size=num_test_classes, replace=False)\n",
    "train_classes = list(set(class_indices.keys()) - set(test_classes))\n",
    "\n",
    "# Получение индексов для обучающей и тестовой выборок\n",
    "train_indices = [idx for cls in train_classes for idx in class_indices[cls]]\n",
    "test_indices = [idx for cls in test_classes for idx in class_indices[cls]]\n",
    "\n",
    "# Создание обучающей и тестовой выборок\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=6)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=6)"
   ],
   "id": "90fe7e47df118580",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T12:08:33.641667Z",
     "start_time": "2024-10-08T12:08:33.628668Z"
    }
   },
   "cell_type": "code",
   "source": "test_loader",
   "id": "2daf58a54c256514",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 10,
   "source": [
    "def get_embeddings_batch(model, imgs_batch):\n",
    "    embeddings = []\n",
    "    for img in imgs_batch:\n",
    "        # Убедимся, что изображение имеет правильную форму и тип\n",
    "        if img.ndim == 2:  # Если изображение чёрно-белое, конвертируем в RGB\n",
    "            img = np.stack([img]*3, axis=-1)\n",
    "        elif img.shape[0] == 3:\n",
    "            img = img.transpose(1, 2, 0)  # Преобразуем из (C, H, W) в (H, W, C)\n",
    "        elif img.shape[2] != 3:\n",
    "            img = img[:, :, :3]  # Оставляем только первые 3 канала\n",
    "        img = img.astype(np.uint8)\n",
    "        emb = model.get_feat(img)\n",
    "        embeddings.append(emb)\n",
    "    embeddings = np.stack(embeddings)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def prepare_and_save_embeddings(data_loader, embedder_r50, embedder_r100, csv_filename):\n",
    "    data = []\n",
    "    for batch_idx, (imgs, labels) in enumerate(data_loader):\n",
    "        labels = labels.numpy()\n",
    "        \n",
    "        # Получаем эмбеддинги для текущего батча\n",
    "        embeddings_r50 = get_embeddings_batch(embedder_r50, imgs)\n",
    "        embeddings_r100 = get_embeddings_batch(embedder_r100, imgs)\n",
    "        \n",
    "        # Собираем данные\n",
    "        for i in range(len(labels)):\n",
    "            data.append({\n",
    "                'label': int(labels[i]),\n",
    "                'emb_r50': embeddings_r50[i].tolist(),\n",
    "                'emb_r100': embeddings_r100[i].tolist()\n",
    "            })\n",
    "        \n",
    "        # Опционально: вывод прогресса\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Processed {batch_idx + 1} batches\")\n",
    "    \n",
    "    # Конвертируем в DataFrame и сохраняем\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Embeddings saved to {csv_filename}\")"
   ],
   "id": "4fa3838f69a28e42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "58ac3639f4000449",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:04:17.688983Z",
     "start_time": "2024-10-09T07:48:20.279944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Загрузка CSV\n",
    "df = pd.read_csv('train_embeddings.csv')\n",
    "\n",
    "# Преобразование эмбеддингов из строк в массивы\n",
    "df['emb_r50'] = df['emb_r50'].progress_apply(lambda x: np.array(eval(x))[0])\n",
    "df['emb_r100'] = df['emb_r100'].progress_apply(lambda x: np.array(eval(x))[0])\n",
    "\n",
    "# Сохраняем в новый CSV или бинарный формат, например, .parquet для ускорения загрузки\n",
    "df.to_parquet('train_embeddings.parquet')"
   ],
   "id": "81ab188d142bba63",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 448575/448575 [07:28<00:00, 1001.22it/s]\n",
      "100%|██████████| 448575/448575 [07:27<00:00, 1002.92it/s]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:35:02.027727Z",
     "start_time": "2024-10-09T08:35:02.013729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, parquet_file):\n",
    "        # Загрузка предобработанных данных\n",
    "        self.data = pd.read_parquet(parquet_file)\n",
    "        self.labels = self.data['label'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        emb_r50 = self.data.iloc[idx]['emb_r50']\n",
    "        emb_r100 = self.data.iloc[idx]['emb_r100']\n",
    "        label = self.labels[idx]\n",
    "        # Конвертируем эмбеддинги в тензоры\n",
    "        emb_r50 = torch.tensor(emb_r50, dtype=torch.float32)\n",
    "        emb_r100 = torch.tensor(emb_r100, dtype=torch.float32)\n",
    "        return emb_r50, emb_r100, label"
   ],
   "id": "4f87a2a7665decce",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:32:10.955596Z",
     "start_time": "2024-10-09T08:32:04.317483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 256\n",
    "\n",
    "# Создаём датасеты из CSV файлов\n",
    "train_dataset = EmbeddingDataset('train_embeddings.parquet')\n",
    "test_dataset = EmbeddingDataset('test_embeddings.parquet')"
   ],
   "id": "fb1f51e43337616e",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T08:32:10.970595Z",
     "start_time": "2024-10-09T08:32:10.958601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Создаём DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ],
   "id": "e9dadcd300deecda",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:32:06.907103Z",
     "start_time": "2024-10-09T09:32:06.894104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EmbeddingMapper(nn.Module):\n",
    "    def __init__(self, input_dim=512, output_dim=512):\n",
    "        super(EmbeddingMapper, self).__init__()\n",
    "        # self.model = nn.Sequential(\n",
    "        #     nn.Linear(input_dim, 1024),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.BatchNorm1d(1024),\n",
    "        #     nn.Linear(1024, 1024),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.BatchNorm1d(1024),\n",
    "        #     nn.Linear(1024, output_dim)\n",
    "        # )\n",
    "        self.lin1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024))\n",
    "        self.lin2 = nn.Sequential(\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2048))\n",
    "        self.lin3 = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024))\n",
    "        self.lin4 = nn.Linear(1024, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.lin1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.lin4(x)\n",
    "        return x"
   ],
   "id": "92fdb17be272b4d3",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:32:07.417107Z",
     "start_time": "2024-10-09T09:32:07.374107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = EmbeddingMapper(input_dim=512, output_dim=512).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Устанавливаем weight_decay для L2-регуляризации\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ],
   "id": "c018a9e9e22f4e08",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:35:53.830479Z",
     "start_time": "2024-10-09T09:32:07.980114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_similarity_torch(x1, x2):\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    return cos(x1, x2)\n",
    "\n",
    "num_epochs = 4\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    total_cosine_sim = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for inputs, targets, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "    \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "        cosine_sim = cosine_similarity_torch(outputs, targets)\n",
    "        total_cosine_sim += cosine_sim.sum().item()\n",
    "        total_samples += inputs.size(0)\n",
    "    \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    avg_cosine_sim = total_cosine_sim / total_samples\n",
    "    print(f'Zero shot cosine similarity: {avg_cosine_sim} ')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    for inputs, targets, _ in tqdm(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Оценка на тестовой выборке\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        total_cosine_sim = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, targets, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            cosine_sim = cosine_similarity_torch(outputs, targets)\n",
    "            total_cosine_sim += cosine_sim.sum().item()\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "        test_loss = test_loss / len(test_loader.dataset)\n",
    "        avg_cosine_sim = total_cosine_sim / total_samples\n",
    "    \n",
    "    torch.save(model.state_dict(), f'checkpoints/refactor_2_embedding_mapper{epoch}.pth')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, '\n",
    "          f'Test Loss: {test_loss:.4f}, Cosine Similarity: {avg_cosine_sim:.4f}')"
   ],
   "id": "a8848ffd44109495",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero shot cosine similarity: -0.0028013435777535867 \n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [00:51<00:00, 33.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Train Loss: 0.3303, Test Loss: 0.2942, Cosine Similarity: 0.8638\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [00:51<00:00, 34.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4, Train Loss: 0.2713, Test Loss: 0.2780, Cosine Similarity: 0.8719\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [00:52<00:00, 33.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4, Train Loss: 0.2601, Test Loss: 0.2722, Cosine Similarity: 0.8747\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [01:08<00:00, 25.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4, Train Loss: 0.2545, Test Loss: 0.2676, Cosine Similarity: 0.8770\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:35:53.845479Z",
     "start_time": "2024-10-09T09:35:53.831479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model = EmbeddingMapper(input_dim=512, output_dim=512).to(device)\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# Устанавливаем weight_decay для L2-регуляризации\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-5)"
   ],
   "id": "785aef803b745c74",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:44:40.309887Z",
     "start_time": "2024-10-09T09:35:53.846479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 10\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    total_cosine_sim = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for inputs, targets, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "    \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "        cosine_sim = cosine_similarity_torch(outputs, targets)\n",
    "        total_cosine_sim += cosine_sim.sum().item()\n",
    "        total_samples += inputs.size(0)\n",
    "    \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    avg_cosine_sim = total_cosine_sim / total_samples\n",
    "    print(f'Zero shot cosine similarity: {avg_cosine_sim} ')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    for inputs, targets, _ in tqdm(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Оценка на тестовой выборке\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        total_cosine_sim = 0.0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, targets, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            cosine_sim = cosine_similarity_torch(outputs, targets)\n",
    "            total_cosine_sim += cosine_sim.sum().item()\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "        test_loss = test_loss / len(test_loader.dataset)\n",
    "        avg_cosine_sim = total_cosine_sim / total_samples\n",
    "    \n",
    "    torch.save(model.state_dict(), f'checkpoints/refactor_2_stage2_embedding_mapper{epoch}.pth')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, '\n",
    "          f'Test Loss: {test_loss:.4f}, Cosine Similarity: {avg_cosine_sim:.4f}')"
   ],
   "id": "de86a95aa5e97a87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero shot cosine similarity: 0.8770138735102411 \n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [00:51<00:00, 33.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.2236, Test Loss: 0.2333, Cosine Similarity: 0.8938\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [00:51<00:00, 33.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.2168, Test Loss: 0.2316, Cosine Similarity: 0.8946\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [00:51<00:00, 34.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.2158, Test Loss: 0.2308, Cosine Similarity: 0.8949\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [00:51<00:00, 34.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.2151, Test Loss: 0.2302, Cosine Similarity: 0.8952\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [00:51<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.2145, Test Loss: 0.2296, Cosine Similarity: 0.8955\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [00:51<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.2141, Test Loss: 0.2292, Cosine Similarity: 0.8957\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [00:52<00:00, 33.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.2137, Test Loss: 0.2287, Cosine Similarity: 0.8959\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [00:51<00:00, 33.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.2133, Test Loss: 0.2287, Cosine Similarity: 0.8959\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [00:51<00:00, 34.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.2130, Test Loss: 0.2283, Cosine Similarity: 0.8961\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1753/1753 [00:58<00:00, 30.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.2127, Test Loss: 0.2281, Cosine Similarity: 0.8962\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:47:25.744630Z",
     "start_time": "2024-10-09T09:47:25.329628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    total_cosine_sim = 0.0\n",
    "    total_samples = 0\n",
    "    similarities = []\n",
    "    for inputs, targets, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        cosine_sim = cosine_similarity_torch(outputs, targets)\n",
    "        similarities.append(cosine_sim.detach().cpu().numpy())\n",
    "        total_cosine_sim += cosine_sim.sum().item()\n",
    "        total_samples += inputs.size(0)\n"
   ],
   "id": "7ed34d8abfb40165",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m      3\u001B[0m     test_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-09T09:47:13.960640Z"
    }
   },
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt",
   "id": "bac7b43545d9e0ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[44], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhist\u001B[49m\u001B[43m(\u001B[49m\u001B[43msimilarities\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\torch_env_hack\\lib\\site-packages\\matplotlib\\pyplot.py:3440\u001B[0m, in \u001B[0;36mhist\u001B[1;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, data, **kwargs)\u001B[0m\n\u001B[0;32m   3415\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mhist)\n\u001B[0;32m   3416\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhist\u001B[39m(\n\u001B[0;32m   3417\u001B[0m     x: ArrayLike \u001B[38;5;241m|\u001B[39m Sequence[ArrayLike],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3438\u001B[0m     BarContainer \u001B[38;5;241m|\u001B[39m Polygon \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mlist\u001B[39m[BarContainer \u001B[38;5;241m|\u001B[39m Polygon],\n\u001B[0;32m   3439\u001B[0m ]:\n\u001B[1;32m-> 3440\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m gca()\u001B[38;5;241m.\u001B[39mhist(\n\u001B[0;32m   3441\u001B[0m         x,\n\u001B[0;32m   3442\u001B[0m         bins\u001B[38;5;241m=\u001B[39mbins,\n\u001B[0;32m   3443\u001B[0m         \u001B[38;5;28mrange\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mrange\u001B[39m,\n\u001B[0;32m   3444\u001B[0m         density\u001B[38;5;241m=\u001B[39mdensity,\n\u001B[0;32m   3445\u001B[0m         weights\u001B[38;5;241m=\u001B[39mweights,\n\u001B[0;32m   3446\u001B[0m         cumulative\u001B[38;5;241m=\u001B[39mcumulative,\n\u001B[0;32m   3447\u001B[0m         bottom\u001B[38;5;241m=\u001B[39mbottom,\n\u001B[0;32m   3448\u001B[0m         histtype\u001B[38;5;241m=\u001B[39mhisttype,\n\u001B[0;32m   3449\u001B[0m         align\u001B[38;5;241m=\u001B[39malign,\n\u001B[0;32m   3450\u001B[0m         orientation\u001B[38;5;241m=\u001B[39morientation,\n\u001B[0;32m   3451\u001B[0m         rwidth\u001B[38;5;241m=\u001B[39mrwidth,\n\u001B[0;32m   3452\u001B[0m         log\u001B[38;5;241m=\u001B[39mlog,\n\u001B[0;32m   3453\u001B[0m         color\u001B[38;5;241m=\u001B[39mcolor,\n\u001B[0;32m   3454\u001B[0m         label\u001B[38;5;241m=\u001B[39mlabel,\n\u001B[0;32m   3455\u001B[0m         stacked\u001B[38;5;241m=\u001B[39mstacked,\n\u001B[0;32m   3456\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m: data} \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}),\n\u001B[0;32m   3457\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3458\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\torch_env_hack\\lib\\site-packages\\matplotlib\\__init__.py:1473\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[1;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1470\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m   1471\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1472\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1473\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\n\u001B[0;32m   1474\u001B[0m             ax,\n\u001B[0;32m   1475\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mmap\u001B[39m(sanitize_sequence, args),\n\u001B[0;32m   1476\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m{k: sanitize_sequence(v) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mitems()})\n\u001B[0;32m   1478\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1479\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[0;32m   1480\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[1;32m~\\.conda\\envs\\torch_env_hack\\lib\\site-packages\\matplotlib\\axes\\_axes.py:6914\u001B[0m, in \u001B[0;36mAxes.hist\u001B[1;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001B[0m\n\u001B[0;32m   6911\u001B[0m     stacked \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   6913\u001B[0m \u001B[38;5;66;03m# Massage 'x' for processing.\u001B[39;00m\n\u001B[1;32m-> 6914\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mcbook\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reshape_2D\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mx\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6915\u001B[0m nx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(x)  \u001B[38;5;66;03m# number of datasets\u001B[39;00m\n\u001B[0;32m   6917\u001B[0m \u001B[38;5;66;03m# Process unit information.  _process_unit_info sets the unit and\u001B[39;00m\n\u001B[0;32m   6918\u001B[0m \u001B[38;5;66;03m# converts the first dataset; then we convert each following dataset\u001B[39;00m\n\u001B[0;32m   6919\u001B[0m \u001B[38;5;66;03m# one at a time.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\torch_env_hack\\lib\\site-packages\\matplotlib\\cbook.py:1462\u001B[0m, in \u001B[0;36m_reshape_2D\u001B[1;34m(X, name)\u001B[0m\n\u001B[0;32m   1460\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1461\u001B[0m         is_1d \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m-> 1462\u001B[0m xi \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masanyarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1463\u001B[0m nd \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mndim(xi)\n\u001B[0;32m   1464\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m nd \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\torch_env_hack\\lib\\site-packages\\torch\\_tensor.py:757\u001B[0m, in \u001B[0;36mTensor.__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m    755\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(Tensor\u001B[38;5;241m.\u001B[39m__array__, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    756\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 757\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    758\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    759\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mTypeError\u001B[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "execution_count": null,
   "source": "plt.hist(similarities)",
   "id": "26bd3453bf55f5e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2e154209bb130634"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
